.\" Automatically generated by Pod::Man 2.25 (Pod::Simple 3.16)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.ie \nF \{\
.    de IX
.    tm Index:\\$1\t\\n%\t"\\$2"
..
.    nr % 0
.    rr F
.\}
.el \{\
.    de IX
..
.\}
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "RAWTEXTFREQ 1p"
.TH RAWTEXTFREQ 1p "2008-06-03" "perl v5.14.2" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
rawtextFreq.pl \- Compute Information Content from Raw / Plain Text
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.Vb 4
\& rawtextFreq.pl \-\-outfile OUTFILE [\-\-stopfile=STOPFILE]
\&               {\-\-stdin | \-\-infile FILE [\-\-infile FILE ...]} 
\&                [\-\-wnpath WNPATH] [\-\-resnik] [\-\-smooth=SCHEME] 
\&                | \-\-help | \-\-version
.Ve
.SH "OPTIONS"
.IX Header "OPTIONS"
\&\fB\-\-outfile\fR=\fIfilename\fR
.PP
.Vb 1
\&    The name of a file to which output should be written
.Ve
.PP
\&\fB\-\-stopfile\fR=\fIfilename\fR
.PP
.Vb 4
\&    A file containing a list of stop listed words that will not be
\&    considered in the frequency counts.  A sample file can be down\-
\&    loaded from
\&    http://www.d.umn.edu/~tpederse/Group01/WordNet/words.txt
.Ve
.PP
\&\fB\-\-wnpath\fR=\fIpath\fR
.PP
.Vb 2
\&    Location of the WordNet data files (e.g.,
\&    /usr/local/WordNet\-3.0/dict)
.Ve
.PP
\&\fB\-\-resnik\fR
.PP
.Vb 1
\&    Use Resnik (1995) frequency counting
.Ve
.PP
\&\fB\-\-smooth\fR=\fI\s-1SCHEME\s0\fR
.PP
.Vb 2
\&    Smoothing should used on the probabilities computed.  SCHEME can
\&    only be ADD1 at this time
.Ve
.PP
\&\fB\-\-help\fR
.PP
.Vb 1
\&    Show a help message
.Ve
.PP
\&\fB\-\-version\fR
.PP
.Vb 1
\&    Display version information
.Ve
.PP
\&\fB\-\-stdin\fR
.PP
.Vb 2
\&    Read from the standard input the text that is to be used for
\&    counting the frequency of words.
.Ve
.PP
\&\fB\-\-infile\fR=\fI\s-1PATTERN\s0\fR
.PP
.Vb 5
\&    The name of a raw text file to be used to count word frequencies.
\&    This can actually be a filename, a directory name, or a pattern (as
\&    understood by Perl\*(Aqs glob() function).  If the value is a directory
\&    name, then all the files in that directory and its subdirectories will
\&    be used.
\&
\&    If you are looking for some interesting files to use, check out
\&    Project Gutenberg: <http://www.gutenberg.org>.
\&
\&    This option may be given more than once (if more than one file
\&    should be used).
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
This program reads a corpus of plain text and computes frequency 
counts from that corpus and then uses those to determine the 
information content of each synset in WordNet. In brief it does this 
by first assigning counts to each synset for which it obtains
a frequency count in the corpus, and then those counts are 
propagated up the WordNet hierarchy. More details on this process
can be found in the documentation of the lin, res, and jcn measures
in WordNet::Similarity and in the publication by Patwardhan, et. al. 
(2003) referred to below.
.PP
The utility programs BNCFreq.pl, SemCorRawFreq.pl, 
treebankFreq.pl, brownFreq.pl all function in exactly the same 
way as this plain text program (rawtextFreq.pl), except that they 
include the ability to deal with the format of the corpus with which
they are used.
.PP
None of these programs requires sense-tagged text; instead they simply  
distribute the counts of the observed form of word to all the synsets 
in the corpus to which it could be associated. The different forms of a 
word are found via the validForms and querySense methods of 
WordNet::QueryData.
.PP
For example, if the observed word is 'bank', then a count is given to 
the synsets associated with the financial institution, a river shore, 
the act of turning a plane, etc.
.SS "Distributing Counts to Synsets"
.IX Subsection "Distributing Counts to Synsets"
If the corpora is sense-tagged, then distributing the counts of 
sense-tagged words to synsets is trivial; you increment the count of 
each synset for which you have a sense tagged instance. It is very hard 
to obtain large quantities of sense tagged text, so in general it is not 
feasible to obtain information content values from large sense-tagged 
corpora.
.PP
As such this program and the related *Freq.pl utilities are all trying 
to increment the counts of synsets based on the occurence of raw 
untagged word forms. In this case it is less obvious how to proceed. 
This program supports two methods for distributing the counts of an 
observed word forms in untagged text to synsets.
.PP
One is our default method, and we refer to the other as Resnik 
counting. In our default counting scheme, each synset receives 
the total count of each word form associated with it.
.PP
Suppose the word 'bank' can be associated with six different 
synets. In our default scheme each of those synsets would receive
a count for each occurrence of 'bank'. In Resnik counting, the
count would be divided between the possible synsets, so
in this case each synset would get one sixth (1/6) of the total
count.
.SS "How are These Counts Used?"
.IX Subsection "How are These Counts Used?"
This program maps word forms to synsets. These synset counts are then
propagated up the WordNet hierarchy to arrive at Information Content 
values for each synset, which are then used by the Lin (lin), Resnik 
(res), and Jiang & Conrath (jcn) measures of semantic similarity.
.PP
By default these measures use counts derived from the cntlist file
provided by WordNet, which is based on frequency counts 
from the sense-tagged SemCor corpus. This consists of approximately
200,000 sense tagged tokens taken from the Brown Corpus and 
the Red Badge of Courage.
.PP
A file called ic\-semcor.dat is created during installation of 
WordNet::Similarity from cntlist. In fact, the util program 
semCorFreq.pl is used to do this. This is the only one of the *Freq.pl 
utility programs that uses sense tagged text, and in fact it only uses 
the counts from cntlist, not the actual sense tagged text.
.PP
This program simply creates an alternative version of the ic\-semcor.dat 
file based on counts obtained from raw untagged text.
.SS "Why Use This Program?"
.IX Subsection "Why Use This Program?"
The default information content file (ic\-semcor.dat) is based on SemCor, 
which includes sense tagged portions of the Brown Corpus and the Red 
Badge of Courage. It has the advantage of being sense tagged, but is 
from a rather limited domain and is somewhat small in size (200,000 
sense tagged tokens).
.PP
If you are working in a different domain or have access to a larger 
quantity of corpora, you might find that this program provides 
information content values that better reflect your underlying domain or 
problem.
.SS "How can these counts be reliable if they aren't based on sense tagged text?"
.IX Subsection "How can these counts be reliable if they aren't based on sense tagged text?"
Remember once the counts are given to a synset, those counts
are propogated upwards, so that each synset receives the counts of
its children. These are then used in the calculation of the information
content of each synset, which is simply :
.PP
.Vb 1
\&        information content (synset) = \- log [probability (synset)]
.Ve
.PP
More details on this calculation and how they are used in the res,
lin, and jcn measures can be found in the WordNet::Similarity module
doumentation, and in the following publication:
.PP
.Vb 5
\& Using Measures of Semantic Relatedness for Word Sense Disambiguation 
\& (Patwardhan, Banerjee and Pedersen) \- Appears in the Proceedings of 
\& the Fourth International Conference on Intelligent Text Processing and 
\& Computational Linguistics, pp. 241\-257, February 17\-21, 2003, Mexico City.
\& L<http://www.d.umn.edu/~tpederse/Pubs/cicling2003\-3.pdf>
.Ve
.PP
We believe that a propagation effect will result in concentrations or
clusters of information content values in the WordNet hierarchy. For 
example, if you have a text about banking, while the different counts of
\&\*(L"bank\*(R" will be dispersed around WordNet, there will also be other
financial terms that occur with bank that will occur near the financial
synset in WordNet, and lead to a concentration of counts in that
region of WordNet. It is best to view this as a conjecture or hypothesis
at this time. Evidence for or against would be most interesting.
.PP
You can use raw text of any kind in this program. We sometimes use
text from Project Gutenburg, for example the Complete Works of 
Shakespeare, available from <http://www.gutenberg.org/ebooks/100>
.SH "BUGS"
.IX Header "BUGS"
Report to WordNet::Similarity mailing list :
 http://groups.yahoo.com/group/wn\-similarity <http://groups.yahoo.com/group/wn-similarity>
.SH "SEE ALSO"
.IX Header "SEE ALSO"
utils.pod
.PP
WordNet home page : 
 <http://wordnet.princeton.edu>
.PP
WordNet::Similarity home page :
 http://wn\-similarity.sourceforge.net <http://wn-similarity.sourceforge.net>
.SH "AUTHORS"
.IX Header "AUTHORS"
.Vb 2
\& Ted Pedersen, University of Minnesota, Duluth
\& tpederse at d.umn.edu
\&
\& Satanjeev Banerjee, Carnegie Mellon University, Pittsburgh
\& banerjee+ at cs.cmu.edu
\&
\& Siddharth Patwardhan, University of Utah, Salt Lake City
\& sidd at cs.utah.edu
\&
\& Jason Michelizzi
.Ve
.SH "COPYRIGHT"
.IX Header "COPYRIGHT"
Copyright (c) 2005\-2008, Ted Pedersen, Satanjeev Banerjee, Siddharth Patwardhan and Jason Michelizzi
.PP
This program is free software; you can redistribute it and/or
modify it under the terms of the \s-1GNU\s0 General Public License
as published by the Free Software Foundation; either version 2
of the License, or (at your option) any later version.
This program is distributed in the hope that it will be useful,
but \s-1WITHOUT\s0 \s-1ANY\s0 \s-1WARRANTY\s0; without even the implied warranty of
\&\s-1MERCHANTABILITY\s0 or \s-1FITNESS\s0 \s-1FOR\s0 A \s-1PARTICULAR\s0 \s-1PURPOSE\s0.  See the
\&\s-1GNU\s0 General Public License for more details.
.PP
You should have received a copy of the \s-1GNU\s0 General Public License
along with this program; if not, write to
.PP
.Vb 3
\& Free Software Foundation, Inc.
\& 59 Temple Place \- Suite 330
\& Boston, MA  02111\-1307, USA
.Ve
